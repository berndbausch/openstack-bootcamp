heat_template_version: newton
description: Autoscaling up/down with parameters and outputs

parameters:
  asgsize:
    type: number
    default: 5
    description: Max size of the autoscaling group
    constraints:
      - range: { min: 2, max: 5 }
  nw:
    type: string
    description: The network to connect the instances to
    constraints:
      - allowed_values: [ 'private', 'appnet' ]

resources:
#
# The auto scaling group defines a number of servers
# (between 1 and 5, starting with the desired number of
# 2 servers)
#
  my_servers:
    type: OS::Heat::AutoScalingGroup
    properties:
      cooldown: 10
      desired_capacity: 2
      max_size:  { get_param: asgsize }
      min_size: 1
      resource:
#
# Servers are configured to run a mindless memory user
#
        type: OS::Nova::Server
        properties:
          config_drive: true
          image: 'ubuntu'
          flavor: d3
          networks:
            - network: { get_param: nw }
          metadata: {"metering.server_group": "myapp"}
          user_data_format: RAW
          user_data: 
            get_file: /home/ubuntu/pressure.sh
#
# Scaling policy is linked to autoscaling group
#
  how_to_scale_up:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: my_servers }
      cooldown: 10
      scaling_adjustment: 1
#
  how_to_scale_down:
    type: OS::Heat::ScalingPolicy
    properties:
      adjustment_type: change_in_capacity
      auto_scaling_group_id: { get_resource: my_servers }
      cooldown: 10
      scaling_adjustment: -1
#
# Alarm processing with Ceilometer
# The parameters define the alarm (meter, stats, period,
# threshold, comparison operator). The alarm_actions
# property has Heat generate a URL and defines Heat's
# action when it receives the alarm: Invoking a scaling policy.
#
  memory_high:
    type: OS::Aodh::GnocchiAggregationByResourcesAlarm
    properties:
      description: Scale up if average memory usage > 600MB
      metric: memory.usage
      aggregation_method: mean
      comparison_operator: gt
      threshold: 600
      resource_type: instance
      query: '{"=": {"server_group": "myapp"}}'
      granularity: 60
      evaluation_periods: 1
      alarm_actions:
        - { get_attr: [how_to_scale_up, alarm_url] }

  memory_low:
    type: OS::Aodh::GnocchiAggregationByResourcesAlarm
    properties:
      description: Scale down if average memory usage < 400MB
      metric: memory.usage
      aggregation_method: mean
      comparison_operator: lt
      threshold: 400
      resource_type: instance
      query: '{"=": {"server_group": "myapp"}}'
      granularity: 60
      evaluation_periods: 1
      alarm_actions:
        - { get_attr: [how_to_scale_down, alarm_url] }

outputs:
  scale_up_url:
    description: >
      This URL is the webhook to scale up the group.  You can invoke
      the scale-up operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [how_to_scale_up, alarm_url]}
  scale_down_url:
    description: >
      This URL is the webhook to scale down the group.  You can invoke
      the scale-down operation by doing an HTTP POST to this URL; no
      body nor extra headers are needed.
    value: {get_attr: [how_to_scale_down, alarm_url]}
  asg_size:
    description: >
      This is the current size of the auto scaling group.
    value: {get_attr: [my_servers, current_size]}
  server_list:
    description: >
      This is a list of server names that are part of the group.
    value: {get_attr: [my_servers, outputs_list, name]}

